{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-pedDxgLiVt"
      },
      "source": [
        "Copyright 2023 DeepMind Technologies Limited\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2HG16BSjEkK"
      },
      "source": [
        "# RoboVQA Data Loading and Eval\n",
        "\n",
        "This colab contains example code for interacting with the RoboVQA dataset for\n",
        "training and evaluation.\n",
        "\n",
        "For more experiment results and details about the dataset, see [robovqa.github.io](https://robovqa.github.io)\n",
        "\n",
        "To cite,\n",
        "```bibtex\n",
        "@inproceedings{robovqa2023arxiv,\n",
        "    title={RoboVQA: Multimodal Long-Horizon Reasoning for Robotics},\n",
        "    author={Pierre Sermanet and Tianli Ding and Jeffrey Zhao and Fei Xia and Debidatta Dwibedi and Keerthana Gopalakrishnan and Christine Chan and Gabriel Dulac-Arnold and Sharath Maddineni and Nikhil J Joshi and Pete Florence and Wei Han and Robert Baruch and Yao Lu and Suvir Mirchandani and Peng Xu and Pannag Sanketi and Karol Hausman and Izhak Shafran and Brian Ichter and Yuan Cao},\n",
        "    booktitle={arXiv preprint arXiv:2311.00899},\n",
        "    year={2023}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gYchRy9fV1O"
      },
      "source": [
        "## Explore examples in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sueZV2IIJxNt"
      },
      "outputs": [],
      "source": [
        "#@title Display utils\n",
        "from IPython import display\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def as_gif(images):\n",
        "  # Render the images as the gif:\n",
        "  images[0].save('/tmp/temp.gif', save_all=True, append_images=images[1:], duration=100, loop=0)\n",
        "  gif_bytes = open('/tmp/temp.gif','rb').read()\n",
        "  return gif_bytes\n",
        "\n",
        "\n",
        "def display_image(images):\n",
        "  if len(images) \u003e1 :\n",
        "    result_images = []\n",
        "    for x in images:\n",
        "      result_images.append(Image.fromarray(x))\n",
        "    display.display(display.Image(as_gif(result_images)))\n",
        "  else:\n",
        "    plt_image =Image.fromarray(images[0])\n",
        "    plt.imshow(plt_image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Km3bFLwm7OCJ"
      },
      "outputs": [],
      "source": [
        "#@title Task utils\n",
        "\"\"\"Tasks related utils.\"\"\"\n",
        "\n",
        "import random\n",
        "import re\n",
        "from absl import logging\n",
        "\n",
        "\n",
        "class Task:\n",
        "  \"\"\"A class for handling tags and splits in a given task.\"\"\"\n",
        "\n",
        "  # Tags for default splitting, based on who is talking.\n",
        "  PRED_STARTS = ['Robot:', 'Thought:', 'Action:']\n",
        "  NOPRED_STARTS = ['User:', 'System:']\n",
        "\n",
        "  # Tags surrounding all blocks needing to be predicted by the model.\n",
        "  PRED_START = '\u003cPRED\u003e'\n",
        "  PRED_END = '\u003c/PRED\u003e'\n",
        "  # Tags surrounding only binary answers, typically 'yes' and 'no'.\n",
        "  PRED_ANSWER_BINARY_START = '\u003cPRED:ANSWER:BINARY\u003e'\n",
        "  PRED_ANSWER_BINARY_END = '\u003c/PRED:ANSWER:BINARY\u003e'\n",
        "  # Tags surrounding all discrete answers coming from a limited set of classes,\n",
        "  # e.g. 'yes', 'no', 'halfway there', 'done', '10s', etc.\n",
        "  PRED_ANSWER_DISCRETE_START = '\u003cPRED:ANSWER:DISCRETE\u003e'\n",
        "  PRED_ANSWER_DISCRETE_END = '\u003c/PRED:ANSWER:DISCRETE\u003e'\n",
        "  # Tags surrounding things that constitute an answer to a question,\n",
        "  # the question may be asked by a user or by the model itself.\n",
        "  PRED_ANSWER_START = '\u003cPRED:ANSWER'\n",
        "  PRED_ANSWER_END = '\u003c/PRED:ANSWER'\n",
        "  # Tags that have any sort of short-content value\n",
        "  PRED_ALL_START = '\u003cPRED:'\n",
        "  PRED_ALL_END = '\u003c/PRED:'\n",
        "\n",
        "  TAGS_RE = r'(\u003c/*\\w[:\\w]*\u003e)'\n",
        "\n",
        "  def __init__(self, text):\n",
        "    self.text = text\n",
        "\n",
        "  def get_random_split(self, split_type='speaker'):\n",
        "    splits = self.get_splits(split_type)\n",
        "    return random.choice(splits)\n",
        "\n",
        "  def get_splits(self, split_type='speaker'):\n",
        "    \"\"\"Returns a list of (source, target) split pairs.\"\"\"\n",
        "    if split_type == 'pred':\n",
        "      return self.get_splits_from_tags(\n",
        "          start_tags=[self.PRED_START], end_tags=[self.PRED_END])\n",
        "    elif split_type == 'binary':\n",
        "      return self.get_splits_from_tags(\n",
        "          start_tags=[self.PRED_BINARY_START], end_tags=[self.PRED_BINARY_END])\n",
        "    elif split_type == 'discrete':\n",
        "      return self.get_splits_from_tags(\n",
        "          start_tags=[self.PRED_DISCRETE_START],\n",
        "          end_tags=[self.PRED_DISCRETE_END])\n",
        "    elif split_type == 'answer':\n",
        "      return self.get_splits_from_tags(\n",
        "          start_tags=[self.PRED_ANSWER_START], end_tags=[self.PRED_ANSWER_END])\n",
        "    elif split_type == 'A:':\n",
        "      return self.get_splits_from_tags(start_tags=['A:'], end_tags=[])\n",
        "    elif split_type == 'speaker':\n",
        "      return self.get_splits_from_tags(\n",
        "          start_tags=self.PRED_STARTS, end_tags=self.NOPRED_STARTS)\n",
        "    elif split_type == 'all':\n",
        "      return self.get_splits_from_tags(\n",
        "          start_tags=[self.PRED_ALL_START], end_tags=[self.PRED_ALL_END]\n",
        "      )\n",
        "    else:\n",
        "      raise ValueError('Unknown split type: %s' % split_type)\n",
        "\n",
        "  def get_splits_from_tags(self, start_tags, end_tags):\n",
        "    \"\"\"Returns a list of (source, target) split pairs given start/end tags.\"\"\"\n",
        "    # Find all the first positions of a start element.\n",
        "    split_positions = []\n",
        "    position = 0\n",
        "    while position \u003c len(self.text):\n",
        "      # Find the next start tag given current position.\n",
        "      start_position = self.find_next_tag(position, start_tags)\n",
        "      if start_position is None:\n",
        "        break\n",
        "      # Then find the first end tag after this start tag.\n",
        "      end_position = self.find_next_tag(start_position, end_tags)\n",
        "      if end_position is None:\n",
        "        end_position = len(self.text)\n",
        "      split_positions.append((start_position, end_position))\n",
        "      position = end_position + 1\n",
        "    return self.get_splits_from_positions(split_positions)\n",
        "\n",
        "  def get_splits_from_positions(self, split_positions):\n",
        "    \"\"\"Returns a list of (source, target) split pairs given split positions.\"\"\"\n",
        "    # Create splits.\n",
        "    splits = []\n",
        "    for (split_position, end_position) in split_positions:\n",
        "      source = ''\n",
        "      if split_position \u003e 0:\n",
        "        source = self.text[:split_position]\n",
        "        source = self._remove_tags(source)\n",
        "      target = self.text[split_position:end_position]\n",
        "      target = self._remove_tags(target)\n",
        "      splits.append((source, target))\n",
        "\n",
        "    # If no splits are found, return entire text.\n",
        "    if not splits:\n",
        "      splits = [('', self.text)]\n",
        "\n",
        "    return splits\n",
        "\n",
        "  def find_next_tag(self, position, tags):\n",
        "    tag_position = None\n",
        "    lower_text = self.text.lower()\n",
        "    for tag in tags:\n",
        "      p = lower_text.find(tag.lower(), position)\n",
        "      if p \u003e= 0 and (tag_position is None or p \u003c tag_position):\n",
        "        tag_position = p\n",
        "    return tag_position\n",
        "\n",
        "  def _remove_tags(self, text):\n",
        "    return re.sub(self.TAGS_RE, '', text)\n",
        "\n",
        "  def remove_tags(self):\n",
        "    self.text = self._remove_tags(self.text)\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.text\n",
        "\n",
        "\n",
        "class Tasks():\n",
        "  \"\"\"A class for handling and holding tasks information.\"\"\"\n",
        "\n",
        "  TASK_RE = r'(\u003ctask[:\\w]*\u003e)'\n",
        "  RE_FLAGS = re.IGNORECASE\n",
        "\n",
        "  def __init__(self, tasks_raw=None):\n",
        "    # Contains all tasks for each task type in this Tasks collection\n",
        "    # key: str, task type (tag)\n",
        "    # value: list[str], question-answers which belong to this task type\n",
        "    self.tasks_dict = {}\n",
        "    self.tasks_list = []\n",
        "    self.tasks_types = []\n",
        "    self.tasks_raw = tasks_raw\n",
        "    if tasks_raw is not None:\n",
        "      self.add(tasks_raw)\n",
        "\n",
        "  def add(self, tasks):\n",
        "    self.add_from_text(tasks)\n",
        "\n",
        "  def add_from_dict(self, tasks_dict):\n",
        "    for name, tasks in tasks_dict.items():\n",
        "      if name not in self.tasks_dict:\n",
        "        self.tasks_dict[name] = []\n",
        "      self.tasks_dict[name].extend(tasks)\n",
        "      self.tasks_list.extend(tasks)\n",
        "      self.tasks_types.extend([name] * len(tasks))\n",
        "\n",
        "  def add_from_text(self, text):\n",
        "    task_dict = self.text_to_dict(text)\n",
        "    self.add_from_dict(task_dict)\n",
        "\n",
        "  def text_to_dict(self, text):\n",
        "    \"\"\"Returns all tasks associated with this video.\"\"\"\n",
        "    # Split a serialized string into raw strings of individual tasks\n",
        "    split = re.split(self.TASK_RE, text, flags=self.RE_FLAGS)[1:]\n",
        "    # Construct a dict of\n",
        "    # key: str, task type (tag)\n",
        "    # value: list[str], question-answers which belong to this task type\n",
        "    tasks_dict = {}\n",
        "    i = 0\n",
        "    while i \u003c len(split) - 1:\n",
        "      tag = split[i].strip()\n",
        "      task = split[i+1].lstrip()\n",
        "      if task:\n",
        "        if tag not in tasks_dict:\n",
        "          tasks_dict[tag] = []\n",
        "        tasks_dict[tag].append(task)\n",
        "      i += 2\n",
        "    return tasks_dict\n",
        "\n",
        "  def __str__(self, show_tasks=True):\n",
        "    s_parts = []\n",
        "    s_parts.append('%d task types in %d tasks:\\n' % (\n",
        "        len(self.tasks_dict.keys()), len(self)))\n",
        "    for key in sorted(self.tasks_dict):\n",
        "      tasks = self.tasks_dict[key]\n",
        "      s_parts.append('%s (%d / %d, %.1f%%)' % (\n",
        "          key, len(tasks), len(self), 100 * len(tasks) / float(len(self))))\n",
        "      if show_tasks:\n",
        "        s_parts.append('\\n\\t%s' % str(tasks))\n",
        "      s_parts.append('\\n')\n",
        "    return ''.join(s_parts)\n",
        "\n",
        "  def detailed_str(self):\n",
        "    s_parts = []\n",
        "    s_parts.append('Raw input: %s' % str(self.tasks_raw))\n",
        "    s_parts.append('\\n%s' % self.__str__(show_tasks=True))\n",
        "    return ''.join(s_parts)\n",
        "\n",
        "  def get_stats(self):\n",
        "    return self.__str__(show_tasks=False)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.tasks_list)\n",
        "\n",
        "  def get_tasks_list(self):\n",
        "    return self.tasks_list\n",
        "\n",
        "  def get_tasks_types(self):\n",
        "    return self.tasks_types\n",
        "\n",
        "  def get_random_task(self):\n",
        "    if not self.tasks_list:\n",
        "      raise ValueError('Unexpected empty tasks list')\n",
        "    return random.choice(self.tasks_list)\n",
        "\n",
        "  def sample_task(self, weights):\n",
        "    \"\"\"Sample a task using weights associated with task patterns.\n",
        "\n",
        "    Note: only tasks matching the patterns in the weights dictionary will\n",
        "    be considered, the patterns for which no tasks are found will be ignored.\n",
        "\n",
        "    Args:\n",
        "      weights: a dict assigning weights to task patterns, e.g.\n",
        "        {'\u003ctask:success:.*': .1}.\n",
        "    Returns:\n",
        "      Str, a task string (without task tag).\n",
        "    \"\"\"\n",
        "    # Organize matching tasks by pattern.\n",
        "    matching_tasks = {}\n",
        "    matching_weights = {}\n",
        "    for pattern, weight in weights.items():\n",
        "      for task, tasks in self.tasks_dict.items():\n",
        "        if re.fullmatch(pattern, task, flags=self.RE_FLAGS):\n",
        "          if pattern not in matching_tasks:\n",
        "            matching_tasks[pattern] = []\n",
        "            matching_weights[pattern] = weight\n",
        "          matching_tasks[pattern].extend(tasks)\n",
        "\n",
        "    # Sample a pattern given weights.\n",
        "    if not matching_weights.keys():\n",
        "      logging.warning('No tasks matching weights %s in %s: %s',\n",
        "                      str(weights), self.detailed_str(), str(matching_weights))\n",
        "      return None, None\n",
        "    pattern = random.choices(\n",
        "        list(matching_weights.keys()), list(matching_weights.values()))[0]\n",
        "\n",
        "    # Sample a task given a pattern.\n",
        "    tasks = matching_tasks[pattern]\n",
        "    if not tasks:\n",
        "      raise ValueError('No tasks to sample of type %s in %s'\n",
        "                       % (pattern, self.tasks_raw))\n",
        "    task = random.choice(tasks)\n",
        "    if not task:\n",
        "      raise ValueError((\n",
        "          'No tasks (\"%s\") is returned after choosing pattern %s and'\n",
        "          ' returning random from \"%s\" from %s') % (\n",
        "              task, pattern, matching_tasks[pattern], self.detailed_str()))\n",
        "    return task, pattern\n",
        "\n",
        "\n",
        "def fetch_question_answer(text):\n",
        "  tasks = Tasks(text)\n",
        "  results = []\n",
        "  for i, (task_type, tasks) in enumerate(tasks.tasks_dict.items()):\n",
        "    for task in tasks:\n",
        "      t = Task(task)\n",
        "      splits = t.get_splits('A:')\n",
        "      for split in splits:\n",
        "        question, answer = split\n",
        "        question = question.strip()\n",
        "        answer = answer.strip()\n",
        "        results.append((i, task_type, question, answer))\n",
        "  return results\n",
        "\n",
        "\n",
        "def display_text(text):\n",
        "  question_answers = fetch_question_answer(text)\n",
        "  for i, task_type, question, answer in question_answers:\n",
        "    print('Task %d (type: %s): %s %s' % (i, task_type, question, answer))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcbDUL2S-1KG"
      },
      "outputs": [],
      "source": [
        "#@title Grab the dataset from Google Cloud Storage\n",
        "import tensorflow as tf\n",
        "\n",
        "filepaths = tf.io.gfile.glob('gs://anon_robovqa/tfrecord/train/train*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_sKbw6KfG7g7"
      },
      "outputs": [],
      "source": [
        "#@title  Create a TF Dataset\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "np_iter = dataset.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB_cJIeNBC64"
      },
      "outputs": [],
      "source": [
        "#@title Let's look at an example in this dataset\n",
        "raw_record = next(np_iter)\n",
        "example = tf.train.SequenceExample()\n",
        "example.ParseFromString(raw_record)\n",
        "\n",
        "images = []\n",
        "for bl in example.feature_lists.feature_list.get('images').feature:\n",
        "  code = bl.bytes_list.value[0]\n",
        "  image = tf.image.decode_jpeg(code).numpy()\n",
        "  images.append(image)\n",
        "print('Displayed items are:')\n",
        "print('Video image frames (in GIF format)')\n",
        "print('All VQA tasks, in format of \"\u003cTask num\u003e (task type): \u003cQuestion\u003e \u003cAnswer\u003e\"')\n",
        "display_image(images)\n",
        "display_text(example.feature_lists.feature_list.get(\"texts\").feature[0].bytes_list.value[0].decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bifM17Klfcho"
      },
      "source": [
        "## Evaluate against the dataset using BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r41wJFoqMigN"
      },
      "outputs": [],
      "source": [
        "#@title Additional imports\n",
        "\n",
        "!pip install sacrebleu\n",
        "import sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRFQwswCfjks"
      },
      "outputs": [],
      "source": [
        "#@title Example BLEU score eval from validation set\n",
        "\n",
        "def mock_call_model(images, question):\n",
        "  # Replace this with your model implementation!\n",
        "  return 'This is a mock answer!'\n",
        "\n",
        "\n",
        "def get_eval_example():\n",
        "  eval_filepaths = tf.io.gfile.glob('gs://anon_robovqa/tfrecord/val/val*')\n",
        "  eval_dataset = tf.data.TFRecordDataset(eval_filepaths)\n",
        "  eval_np_iter = eval_dataset.as_numpy_iterator()\n",
        "  eval_raw_record = next(eval_np_iter)\n",
        "  eval_example = tf.train.SequenceExample()\n",
        "  eval_example.ParseFromString(eval_raw_record)\n",
        "  return eval_example\n",
        "\n",
        "\n",
        "def run_eval(call_model):\n",
        "  example = get_eval_example()\n",
        "  images = []\n",
        "  print('Below are sampled eval answers and BLEU scores')\n",
        "  for bl in example.feature_lists.feature_list.get('images').feature:\n",
        "    code = bl.bytes_list.value[0]\n",
        "    image = tf.image.decode_jpeg(code).numpy()\n",
        "    images.append(image)\n",
        "  qa_list = fetch_question_answer(example.feature_lists.feature_list.get(\"texts\").feature[0].bytes_list.value[0].decode('utf-8'))\n",
        "  for _, _, question, answer in qa_list:\n",
        "    pred_answer = call_model(images, question)\n",
        "    bleu = sacrebleu.sentence_bleu(answer, pred_answer)\n",
        "    print(f'Question: {question}\\nAnswer: {answer}\\nPredicted Answer: {pred_answer}\\nBLEU: {bleu}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5WbqRH84wBM"
      },
      "outputs": [],
      "source": [
        "run_eval(mock_call_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vvjXHsS5UwP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "data_loading_and_eval.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "12-GOusmhdmNOzNZ-wwgFum28hwg7-k_p",
          "timestamp": 1698709635132
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
